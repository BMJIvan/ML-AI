{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tf15",
   "display_name": "Python 3.7.8 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"]=[10,10]\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizacion de hiperparamentros (aquellos parametros que no estan dentro del modelo en si, pero afectan su rendimiento)\n",
    "\n",
    "#Hasta ahora hemos visto una manera relativamente sencilla de ver que valores de los hiperparametros funcionan mejor, mediante las curvas de validacion\n",
    "#Estas curvas son muy utiles para darnos informacion a los Data Scientits, pero tienen dos problemas:\n",
    "#1. son metodos graficos, esto significa que necesitan un humano para interpretarlas y no nos permiten automatizar el proceso para encontrar los hiperparametros optimos\n",
    "#2. solo toman un hiperparametro a la vez. Esto significa que hacen que sea mas dificil el evaluar combinaciones de los hiperparametros (si quisieramos evaluar multiples hiperparametros tendriamos que hacer graficas de planos o hiperplanos)\n",
    "\n",
    "#Se veran metodos mas robustos para dado un modelo, encontrar el conjunto de hiperparametros que hace que funcion mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pandas.read_csv(r\"D:\\Estudiar\\MLData\\boston\\Boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"medv\"]=data[\"medv\"]>21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "257"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "sum(data[\"medv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  True  \n",
       "1  396.90   9.14  True  \n",
       "2  392.83   4.03  True  \n",
       "3  394.63   2.94  True  \n",
       "4  396.90   5.33  True  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crim</th>\n      <th>zn</th>\n      <th>indus</th>\n      <th>chas</th>\n      <th>nox</th>\n      <th>rm</th>\n      <th>age</th>\n      <th>dis</th>\n      <th>rad</th>\n      <th>tax</th>\n      <th>ptratio</th>\n      <th>black</th>\n      <th>lstat</th>\n      <th>medv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline de procesamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetN=\"medv\"\n",
    "trainN=data.drop(targetN,axis=1).columns\n",
    "train=data[trainN]\n",
    "target=data[targetN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([ True, False])"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "target.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num=train.select_dtypes([int, float])\n",
    "col_num=data_num.columns\n",
    "\n",
    "data_cat=train.select_dtypes([object])\n",
    "col_cat=data_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se usara un trasformados MultiLabelBinarizer. Es como el LabelBinarizer pero funciona para multiples columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 1, 1, 0, 1, 0, 0]])"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "b=MultiLabelBinarizer()\n",
    "b.fit_transform(\n",
    "    [\n",
    "        [\"gato\",\"patata\",\"rojo\"],\n",
    "        [\"perror\",\"zanahoria\",\"axul\"],\n",
    "        [\"camello\",\"patata\",\"verde\"],\n",
    "        [\"gato\",\"patata\",\"rojo\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['axul', 'camello', 'gato', 'patata', 'perror', 'rojo', 'verde',\n",
       "       'zanahoria'], dtype=object)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "b.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "    def __init__(self,columns):\n",
    "        self.columns=columns\n",
    "\n",
    "    def transform(self, X, **tranform_params):\n",
    "        return pandas.DataFrame(X[self.columns])\n",
    "\n",
    "    def fit(self, X, **fit_params):\n",
    "        return self\n",
    "\n",
    "class BinarizadorMultipleCat(TransformerMixin):\n",
    "    def __init__(self,*args, **kargs):\n",
    "        self.encoder=MultiLabelBinarizer(*args, **kargs)\n",
    "    def fit(self, X, y=None):\n",
    "        #super(BinarizadorMultipleCat,self).fit(X)\n",
    "        self.encoder.fit(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.encoder.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_num=Pipeline([\n",
    "    (\"selecct_num\",ColumnExtractor(columns=col_num)),\n",
    "    (\"escalador\",StandardScaler()),\n",
    "    (\"imputador\",SimpleImputer()),\n",
    "])\n",
    "\n",
    "pipeline_cat=Pipeline([\n",
    "   (\"selector_cat\",ColumnExtractor(columns=col_cat)),\n",
    "  (\"codificador_numerico\",BinarizadorMultipleCat()),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([], shape=(0, 0), dtype=int32)"
      ]
     },
     "metadata": {},
     "execution_count": 79
    }
   ],
   "source": [
    "pipeline_cat.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "pipeline_num.fit_transform(train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_procesado=FeatureUnion([\n",
    "    (\"trans_num\",pipeline_num),\n",
    "    #(\"trans_cat\",pipeline_cat),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pro=pipeline_num.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "train_pro.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def evaluar_modelo(estimador, X, y):\n",
    "    res_estimador=cross_validate(estimador, X, y, scoring=\"roc_auc\",n_jobs=2, cv=5, return_train_score=True)\n",
    "    return res_estimador\n",
    "\n",
    "def see_res():\n",
    "    res_df=pandas.DataFrame(resultados).T\n",
    "    res_cols=res_df.columns\n",
    "    for col in res_df:\n",
    "        res_df[col]=res_df[col].apply(numpy.mean)\n",
    "        res_df[str(col)+\"_idx\"]=res_df[col]/res_df[col].max()\n",
    "    return res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "resultados={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"reg_logistica\"]=evaluar_modelo(LogisticRegression(),train_pro,target)\n",
    "resultados[\"naive_bayes\"]=evaluar_modelo(GaussianNB(),train_pro,target)\n",
    "resultados[\"rf\"]=evaluar_modelo(RandomForestClassifier(),train_pro,target)\n",
    "resultados[\"svc\"]=evaluar_modelo(SVC(),train_pro,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               fit_time  score_time  test_score  train_score  fit_time_idx  \\\n",
       "reg_logistica  0.014928    0.002974    0.914224     0.948886      0.059689   \n",
       "naive_bayes    0.003559    0.000000    0.865827     0.883308      0.014232   \n",
       "rf             0.250090    0.016487    0.914403     0.999995      1.000000   \n",
       "svc            0.012101    0.008097    0.925786     0.970662      0.048388   \n",
       "\n",
       "               score_time_idx  test_score_idx  train_score_idx  \n",
       "reg_logistica        0.180356        0.987511         0.948890  \n",
       "naive_bayes          0.000000        0.935234         0.883313  \n",
       "rf                   1.000000        0.987705         1.000000  \n",
       "svc                  0.491092        1.000000         0.970667  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n      <th>fit_time_idx</th>\n      <th>score_time_idx</th>\n      <th>test_score_idx</th>\n      <th>train_score_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reg_logistica</th>\n      <td>0.014928</td>\n      <td>0.002974</td>\n      <td>0.914224</td>\n      <td>0.948886</td>\n      <td>0.059689</td>\n      <td>0.180356</td>\n      <td>0.987511</td>\n      <td>0.948890</td>\n    </tr>\n    <tr>\n      <th>naive_bayes</th>\n      <td>0.003559</td>\n      <td>0.000000</td>\n      <td>0.865827</td>\n      <td>0.883308</td>\n      <td>0.014232</td>\n      <td>0.000000</td>\n      <td>0.935234</td>\n      <td>0.883313</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>0.250090</td>\n      <td>0.016487</td>\n      <td>0.914403</td>\n      <td>0.999995</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.987705</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>svc</th>\n      <td>0.012101</td>\n      <td>0.008097</td>\n      <td>0.925786</td>\n      <td>0.970662</td>\n      <td>0.048388</td>\n      <td>0.491092</td>\n      <td>1.000000</td>\n      <td>0.970667</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "see_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se selecciona un estimador en funcion de los resultados iniciales y optimizarlo. Elijo el estimador Random Forest por que funciona muy bien en comparacion a los demas y es bastante rapido de entrenar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimador_rf=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-learn tiene dos metodos de optimizacion de hiperparametros, GridSearchCV y RandomizedSearchCV\n",
    "\n",
    "#GridSearchCV funciona realizando una busqueda en una malla, es decir, pasandole un conjunto de posibles opciones de hiperparametros evalue de forma completa cada combinacion de dichos parametros (es decir, el valor 1 del hiperparametro 1 combinado con todos los posibles valores de los demas hiperparametros, el valor 2 del hiperparametros 1 combinado con todos los posibles valores de los demas hiperparametros, etcetera)\n",
    "\n",
    "#La ventaja de utilizar una busqueda de malla es que nos aseguramos de que se han probado todas las combinaciones posibles. El problema es que el proceso requiere mucho tiempo de computacion, y segun que dataset usemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "360 ns ± 57.2 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "import time\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "600 ns ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1 #n ejecuta esta celda una vez, r que ejecute un solo loop\n",
    "def foo():\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "estimador_rf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([  10,  120,  230,  340,  450,  560,  670,  780,  890, 1000])"
      ]
     },
     "metadata": {},
     "execution_count": 42
    }
   ],
   "source": [
    "numpy.linspace(10,1000,10).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_search_rf={\n",
    "    \"criterion\": [\"gini\",\"entropy\"],\n",
    "    \"n_estimators\": numpy.linspace(10,1000,10).astype(int),\n",
    "    \"class_weight\": [None,\"balanced\"]\n",
    "}\n",
    "\n",
    "grid=GridSearchCV(estimator=estimador_rf, param_grid=param_search_rf, scoring=\"roc_auc\",n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV se comporta como un estimador en cuanto a que tienen un metodo fit que usamos para \"entrenarlo\" y que realize la busqueda en malla\n",
    "#Para ver cuanto tiempo tarda en realizar la busqueda usamos %%timeit que evalua el tiempo que tarda una funcion en ejecutarse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2min 41s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "grid.fit(train_pro,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9212749715270725\nRandomForestClassifier(class_weight='balanced', criterion='entropy',\n                       n_estimators=560)\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tras haberlo ajustado, Gridsearch nos devuelve el ranking de todas las variantes evaluadas junto con metricas de su funcionamiento con el atributo cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.DataFrame(grid.cv_results_).sort_values(by=\"rank_test_score\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_gridsearch\"]=evaluar_modelo(grid.best_estimator_, train_pro, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se hara la misma optimizacion de parametros pero usando RandomizedSearchcCV, el cual funciona de forma similar a GridSearchCV, pero en vez de evaluar todas las combinaciones posibles de hiperparametros, se toman n muestras de hiperparametros de dichas distribuciones en vez de valores fijos para hiperparametros continuos\n",
    "\n",
    "#Primero se va a evaluar el funcionamiento de la busqueda aleatoria con los mismos hiperparametros que hemos usado en la busqueda en malla. para \"RandomizedSearchCV\" tenemos que indicarle cuantas variables de hiperparametros utilizar (definidas por el parametro n_iter, por defecto toma 10 variantes). Dado que dicha busqueda tom amuestreos el parametro ya no se llama \"param_grid\" sino \"param_distributions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_ran=RandomizedSearchCV(estimator=estimador_rf, param_distributions=param_search_rf, scoring=\"roc_auc\", n_jobs=2, n_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "49.1 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_ran.fit(train_pro,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9190854649552127\nRandomForestClassifier(class_weight='balanced', criterion='entropy',\n                       n_estimators=450)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_ran.best_score_)\n",
    "print(busqueda_ran.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La busqueda de malla obtivo 0.9212749715270725 contra 0.9190854649552127obtenido por la busqueda aleatoria \n",
    "#sin embargo la busqueda aleatoria ha tardado 8 veces menos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch\"]=evaluar_modelo(grid.best_estimator_,train_pro, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La ventaja del Randomized Search es que nos permite evaluar un espacio de hiperparametros mas amplio para un tiempo de computacion similar\n",
    "#Paara ver esto se ampliara el espacio de busqueda de hiperparametros y hacer 20 muestreos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint \n",
    "\n",
    "param_dist_ran={\n",
    "    \"max_depth\": [3, None],\n",
    "    \"max_features\": randint(1,11),\n",
    "    \"min_samples_split\": randint(2,11),\n",
    "    \"min_samples_leaf\": randint(1,11),\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"n_estimators\": numpy.linspace(10,1000,10).astype(int),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_ran_100=RandomizedSearchCV(estimator=estimador_rf, param_distributions=param_dist_ran, scoring=\"roc_auc\", n_jobs=2, n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "1min 19s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "busqueda_ran_100.fit(train_pro,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.9283126173546341\nRandomForestClassifier(max_depth=3, max_features=5, min_samples_leaf=2,\n                       min_samples_split=7, n_estimators=450)\n"
     ]
    }
   ],
   "source": [
    "print(busqueda_ran_100.best_score_)\n",
    "print(busqueda_ran_100.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La busqueda aleatoria con los nuevos parametros ha tardado un tiempo similar a la busqueda en malla. pero ha obtenido una puntuacion maxima ROC AUC de 0.9283126173546341"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"rf_randomizedsearch_100\"]=evaluar_modelo(busqueda_ran_100.best_estimator_, train_pro, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         fit_time  score_time  test_score  train_score  \\\n",
       "reg_logistica            0.014928    0.002974    0.914224     0.948886   \n",
       "naive_bayes              0.003559    0.000000    0.865827     0.883308   \n",
       "rf                       0.250090    0.016487    0.914403     0.999995   \n",
       "svc                      0.012101    0.008097    0.925786     0.970662   \n",
       "rf_gridsearch            1.759247    0.127154    0.917864     1.000000   \n",
       "rf_randomizedsearch      1.796803    0.115709    0.918571     1.000000   \n",
       "rf_randomizedsearch_100  1.446913    0.106798    0.922525     0.973737   \n",
       "\n",
       "                         fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "reg_logistica                0.008308        0.023385        0.987511   \n",
       "naive_bayes                  0.001981        0.000000        0.935234   \n",
       "rf                           0.139186        0.129661        0.987705   \n",
       "svc                          0.006735        0.063675        1.000000   \n",
       "rf_gridsearch                0.979098        1.000000        0.991443   \n",
       "rf_randomizedsearch          1.000000        0.909992        0.992206   \n",
       "rf_randomizedsearch_100      0.805271        0.839908        0.996477   \n",
       "\n",
       "                         train_score_idx  \n",
       "reg_logistica                   0.948886  \n",
       "naive_bayes                     0.883308  \n",
       "rf                              0.999995  \n",
       "svc                             0.970662  \n",
       "rf_gridsearch                   1.000000  \n",
       "rf_randomizedsearch             1.000000  \n",
       "rf_randomizedsearch_100         0.973737  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n      <th>fit_time_idx</th>\n      <th>score_time_idx</th>\n      <th>test_score_idx</th>\n      <th>train_score_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reg_logistica</th>\n      <td>0.014928</td>\n      <td>0.002974</td>\n      <td>0.914224</td>\n      <td>0.948886</td>\n      <td>0.008308</td>\n      <td>0.023385</td>\n      <td>0.987511</td>\n      <td>0.948886</td>\n    </tr>\n    <tr>\n      <th>naive_bayes</th>\n      <td>0.003559</td>\n      <td>0.000000</td>\n      <td>0.865827</td>\n      <td>0.883308</td>\n      <td>0.001981</td>\n      <td>0.000000</td>\n      <td>0.935234</td>\n      <td>0.883308</td>\n    </tr>\n    <tr>\n      <th>rf</th>\n      <td>0.250090</td>\n      <td>0.016487</td>\n      <td>0.914403</td>\n      <td>0.999995</td>\n      <td>0.139186</td>\n      <td>0.129661</td>\n      <td>0.987705</td>\n      <td>0.999995</td>\n    </tr>\n    <tr>\n      <th>svc</th>\n      <td>0.012101</td>\n      <td>0.008097</td>\n      <td>0.925786</td>\n      <td>0.970662</td>\n      <td>0.006735</td>\n      <td>0.063675</td>\n      <td>1.000000</td>\n      <td>0.970662</td>\n    </tr>\n    <tr>\n      <th>rf_gridsearch</th>\n      <td>1.759247</td>\n      <td>0.127154</td>\n      <td>0.917864</td>\n      <td>1.000000</td>\n      <td>0.979098</td>\n      <td>1.000000</td>\n      <td>0.991443</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>rf_randomizedsearch</th>\n      <td>1.796803</td>\n      <td>0.115709</td>\n      <td>0.918571</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>0.909992</td>\n      <td>0.992206</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>rf_randomizedsearch_100</th>\n      <td>1.446913</td>\n      <td>0.106798</td>\n      <td>0.922525</td>\n      <td>0.973737</td>\n      <td>0.805271</td>\n      <td>0.839908</td>\n      <td>0.996477</td>\n      <td>0.973737</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "see_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PArace que el estimador obtenido con la busqueda aleatoria es de los que mejor funciona\n",
    "\n",
    "#En general, salvo que el espacio de hiperparametros que queramos explorar sea pequeño, es mejor utilizar RandomizedSearch en ver de GridSearchCV. Esto es asi porque en general no existe un unico conjunto de hiperparametros que obtiene el mejor funcionamiento, sino que suelen existir multiples \"areas\" en el espacio dimensional de los hiperparametros que funcionan de forma similar. Al hacer una busqueda aleatoria podemos explorarlas las diversas areas en un tiempo mas reducido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimizacion de parametros dentro de Pipeline\n",
    "\n",
    "#Los algoritmos de busqueda de sklearn siguen la API de transformaciones y estimadores. Esto significa que podemos crear un pipeline e incluir la optimizacion de hiperparametros dentro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "busqueda_ran_10=RandomizedSearchCV(estimator=estimador_rf, param_distributions=param_dist_ran, scoring=\"roc_auc\", n_iter=10)\n",
    "\n",
    "pipeline_estimador=Pipeline(\n",
    "    [\n",
    "        (\"procesado\", pipeline_num),\n",
    "        (\"estimador\", busqueda_ran_10),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora podemos ajustar directamente en los datos originales sin tener que preprocesarlos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "fit() takes 2 positional arguments but 3 were given",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-a7f699cc2069>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline_estimador\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \"\"\"\n\u001b[0;32m    377\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \"\"\"\n\u001b[0;32m    377\u001b[0m         \u001b[0mfit_params_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_fit_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m         \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mlast_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mmessage_clsname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Pipeline'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_idx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m                 **fit_params_steps[name])\n\u001b[0m\u001b[0;32m    308\u001b[0m             \u001b[1;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[1;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[1;34m(transformer, X, y, weight, message_clsname, message, **fit_params)\u001b[0m\n\u001b[0;32m    752\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fit_transform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\xmax1\\Desktop\\tf15\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    700\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: fit() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "pipeline_estimador.fit(train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-optimize es una libreria que implementa multiples metodos para optimizar hiperparametros de forma secuencial\n",
    "\n",
    "#desde jupyter se instala como:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting scikit-optimize\n  Downloading scikit_optimize-0.8.1-py2.py3-none-any.whl (101 kB)\nRequirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\xmax1\\desktop\\tf15\\lib\\site-packages (from scikit-optimize) (0.24.1)\nRequirement already satisfied: joblib>=0.11 in c:\\users\\xmax1\\desktop\\tf15\\lib\\site-packages (from scikit-optimize) (1.0.1)\nRequirement already satisfied: numpy>=1.13.3 in c:\\users\\xmax1\\desktop\\tf15\\lib\\site-packages (from scikit-optimize) (1.20.2)\nCollecting pyaml>=16.9\n  Downloading pyaml-20.4.0-py2.py3-none-any.whl (17 kB)\nRequirement already satisfied: scipy>=0.19.1 in c:\\users\\xmax1\\desktop\\tf15\\lib\\site-packages (from scikit-optimize) (1.6.2)\nCollecting PyYAML\n  Downloading PyYAML-5.4.1-cp37-cp37m-win_amd64.whl (210 kB)\nRequirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\xmax1\\desktop\\tf15\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.1.0)\nInstalling collected packages: PyYAML, pyaml, scikit-optimize\nSuccessfully installed PyYAML-5.4.1 pyaml-20.4.0 scikit-optimize-0.8.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'0.8.1'"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "skopt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#En vez de usar un diccionario con el espacio de hiperparametros que queremos buscar, scikit-optimize necesita pasarle una lista de parametros\n",
    "\n",
    "#skopt es una libreria relativamente nueva, y tienen ciertas limitaciones comparada con scikit-optimize. Por ejemplo, en vez de diccionarios con los nombre con los parametros, espera como inputs listas, no se pueden usar funciones de distribuciones como scipy.randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import space\n",
    "\n",
    "param_espace_skopt=[\n",
    "     space.Integer(3,10), #max_depth\n",
    "     space.Integer(1,11), #max_features\n",
    "     (0.001, 0.99, \"uniform\"), #min_samples_split\n",
    "     (0.001, 0.5, \"uniform\"), #min_samples_leaf\n",
    "     space.Integer(1, 1000), #n_estimators\n",
    "     space.Categorical([\"gini\",\"rntropy\"]), #criterion\n",
    "     space.Categorical([True,False])\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scikit-optimeze necesita que definamos la funcion objetivo, que ira variando en funcion de los parametros elegidos. Dicha funcion tiene que crear el estimador y evaluarlo y devolver la evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "estimador_rf=RandomForestClassifier()\n",
    "\n",
    "def funcion_optimizaable(params):\n",
    "    #params es una seleccion especifica de hiperparametros\n",
    "    max_depth, max_features, min_samples_split, min_samples_leaf, n_estimators, criterion, bootstrap=params\n",
    "\n",
    "    estimador_rf.set_params(\n",
    "        max_depth=max_depth,\n",
    "        max_features=max_features,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        n_estimators=n_estimators,\n",
    "        criterion=criterion\n",
    "    )\n",
    "\n",
    "    return -numpy.mean(cross_val_score(estimador_rf, train_pro, target, cv=5, n_jobs=2, scoring=\"roc_auc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ahora podemos dejar que skopt optimize los outputs de la funcion funcion_optimizable mediante el uso de gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 1\n",
    "resultado_gp=gp_minimize(funcion_optimizaable, param_espace_skopt, n_calls=20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperopt-sklearn es una libreria que trabaja con scikit-learn"
   ]
  }
 ]
}