{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8-candidate"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "tf15",
   "display_name": "tf15",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "9e80d76ea6f7910366ea144e4925c6ce12227515ad9ee1266cb0780bd8ad6c40"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "import pandas\n",
    "import numpy\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"]=[10,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'ntpath' from 'C:\\\\Users\\\\xmax1\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python37\\\\lib\\\\ntpath.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "import os\n",
    "os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seleccion de variables\n",
    "#En esta ocasion vamos a ver las distintas tecnicas de seleccion de variables, que son las tecnicas que nos permiten filtrar las variables que tenemos y elegir aquwllas que realmente estan ayudando al modelo\n",
    "#Â¿Por que querriamos eliminar variables? Generalmente, cuanta mas informacion tenemos sobre cada observacion mejor sera la calidad de nuestras predicciones (cuanto mas sepamos, mas facil sera diferenciar unos casos de otros). No obstante, esto no tiene modelos funcinoen peor, por ejemplo debido a errores de medicion. \n",
    "#Seleccionar variables tiene varias ventajas. En primer lugar, como hemos dicho, puede mejorar las puntuaciones de los modelos (eliminando parte del ruido en los datos), por otra parte, reducir el numero de variables independientes reduce la complejidad del modelo, reduciendo asi el efecto de sobreajuste del modelo, Ademas, tener variables independientes y midelos mas simples significa que nuestros modelos son mas rapidos de entrenar, y podemps entrenarlos con mas datos en las mismas maquinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pandas.read_csv(r\"D:\\Estudiar\\MLData\\boston\\Boston.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "    black  lstat  medv  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>crim</th>\n      <th>zn</th>\n      <th>indus</th>\n      <th>chas</th>\n      <th>nox</th>\n      <th>rm</th>\n      <th>age</th>\n      <th>dis</th>\n      <th>rad</th>\n      <th>tax</th>\n      <th>ptratio</th>\n      <th>black</th>\n      <th>lstat</th>\n      <th>medv</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>2.31</td>\n      <td>0</td>\n      <td>0.538</td>\n      <td>6.575</td>\n      <td>65.2</td>\n      <td>4.0900</td>\n      <td>1</td>\n      <td>296</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>6.421</td>\n      <td>78.9</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.07</td>\n      <td>0</td>\n      <td>0.469</td>\n      <td>7.185</td>\n      <td>61.1</td>\n      <td>4.9671</td>\n      <td>2</td>\n      <td>242</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>6.998</td>\n      <td>45.8</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>2.18</td>\n      <td>0</td>\n      <td>0.458</td>\n      <td>7.147</td>\n      <td>54.2</td>\n      <td>6.0622</td>\n      <td>3</td>\n      <td>222</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>36.2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "7084\n"
     ]
    }
   ],
   "source": [
    "print(data.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables numericas\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num_im_nor=pandas.DataFrame(normalize(SimpleImputer(strategy=\"median\").fit_transform(data)),columns=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables categoricas\n",
    "#Usar sklearn.preprocessing.LabelBinarizer para hacer un 1 hot encoding y codificarlas como vectores\n",
    "#Usar la funcion get_dummies de pandas\n",
    "#En general la opcion recomendada es la de usar LabelBinarizer ya que esto nos crea un transformador de scikit learn que poddemos usar en pipelines y para transformar nuevas observaciones\n",
    "#data_cat_dum=pandas.get_dummies(data_cat,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables ordinales\n",
    "#Yendo al diccionario de datos (donde se describen todas las variables) hay varias variables que son ordinales (ordinal, basicamente evaluaciones de una condicion de la casa definidas en una escala no numerica pero que tiene cierto orden (de \"mejor\" a \"peor\")\n",
    "\n",
    "#scikit_learn no tienen un codificador ordinal (Se puede usar el label encoder) Tenemos tres opciones:\n",
    "#1. implementar nuestro propio OrdinalEncoder\n",
    "#2. Utilizar la implementacion del paquete scikit_learn.contrib.categorical_encoding, que podemos instalar con pip install category_encoders\n",
    "#dict_var_ord={\n",
    "#    \"calidad\":[\"buena\",\"mala\"],\n",
    "#    \"altura\":[\"NA\",\"baja\",\"alta\"]\n",
    "#}\n",
    "\n",
    "#col=list(dict_var_ord.keys())\n",
    "#data_ord=data[col]\n",
    "#for col_ord,valores in dict_var_ord.items():\n",
    "#    data_ord[col_ord]=[data_ord[col_ord].astype(\"category\").cat.set_categories(valores).cat.codes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "targetN=\"medv\"\n",
    "trainN=[col for col in data.columns if col!=targetN]\n",
    "train=data[trainN]\n",
    "target=data[targetN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#La funcion cross_validate que es una version mas flexible que cross_val_score. Evaluaremos usando la raiz del error cuadratico medio (RMSE)\n",
    "\n",
    "def rmse(y_real,y_pred):\n",
    "    return numpy.sqrt(mean_squared_error(y_real,y_pred))\n",
    "\n",
    "def rmse_cv(estimator,X,y):\n",
    "    y_pred=estimator.predict(X)\n",
    "    return rmse(y,y_pred)\n",
    "\n",
    "#scorer = {'main': 'accuracy',\n",
    "#          'custom': make_scorer(score_func=rmse_cv,greater_is_better=False)}\n",
    "\n",
    "#scorer = make_scorer(rmse_cv, greater_is_better=False)\n",
    "\n",
    "scorer={'accuracy': make_scorer(rmse_cv,greater_is_better=False),'prec': 'precision'}\n",
    "\n",
    "res=cross_validate(LinearRegression(),train,target,scoring=rmse_cv,n_jobs=2,cv=10,return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([4.83355236, 4.78351694, 4.81830623, 4.55759835, 4.61902872,\n",
       "       4.72902737, 4.82982623, 3.45820725, 4.6461054 , 4.81550033])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "res[\"train_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(estimator,X,y):\n",
    "    res_estimator=cross_validate(LinearRegression(),train,target,scoring=rmse_cv,n_jobs=2,cv=10,return_train_score=True)\n",
    "    return res_estimator\n",
    "\n",
    "resultados={}\n",
    "\n",
    "def see_res():\n",
    "    res_df=pandas.DataFrame(resultados).T\n",
    "    res_cols=res_df.columns\n",
    "    for col in res_df:\n",
    "        res_df[col]=res_df[col].apply(numpy.mean)\n",
    "        res_df[str(col)+\"_idx\"]=res_df[col]/res_df[col].min()\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                          fit_time  score_time  test_score  train_score  \\\n",
       "reg_lineal_sin_seleccion  0.004801    0.004001    5.180846     4.609067   \n",
       "svr_sin_seleccion         0.004802    0.003200    5.180846     4.609067   \n",
       "rf_sin_seleccion          0.004719    0.003819    5.180846     4.609067   \n",
       "\n",
       "                          fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "reg_lineal_sin_seleccion      1.017410        1.250250             1.0   \n",
       "svr_sin_seleccion             1.017557        1.000000             1.0   \n",
       "rf_sin_seleccion              1.000000        1.193202             1.0   \n",
       "\n",
       "                          train_score_idx  \n",
       "reg_lineal_sin_seleccion              1.0  \n",
       "svr_sin_seleccion                     1.0  \n",
       "rf_sin_seleccion                      1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n      <th>fit_time_idx</th>\n      <th>score_time_idx</th>\n      <th>test_score_idx</th>\n      <th>train_score_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reg_lineal_sin_seleccion</th>\n      <td>0.004801</td>\n      <td>0.004001</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.017410</td>\n      <td>1.250250</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion</th>\n      <td>0.004802</td>\n      <td>0.003200</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.017557</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion</th>\n      <td>0.004719</td>\n      <td>0.003819</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.000000</td>\n      <td>1.193202</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "resultados[\"reg_lineal_sin_seleccion\"]=evaluate_model(LinearRegression(),train,target)\n",
    "resultados[\"svr_sin_seleccion\"]=evaluate_model(SVR(),train,target)\n",
    "resultados[\"rf_sin_seleccion\"]=evaluate_model(RandomForestRegressor(),train,target)\n",
    "\n",
    "see_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodos de filtrado\n",
    "#Los metodos de filtrado usan metodos estadisticos para seleccionar las variables que proporcionan la mayor cantidad de informacion. Estos metodos se aplican de forma previa a entrenar el modelo (preprocesado), y son completamente independientes de la eleccion del estimador. Generalmente funcionan definiendo una funcion de evaluacion S(xk_i,y_k), evaluando cada variable independientemente para cada observacion respecto a la variable objetivo de dicha observacion, y eligiendo aquellas k variables que mejor funcionan\n",
    "\n",
    "#Scikit-learn tiene la siguientes funciones de evaluacion:\n",
    "    #Para regresion: f_regression, mutual_info_regression\n",
    "    #Para clasificacion: ch12, f_classif, mutual_info_classif\n",
    "\n",
    "#f_regression y f_classif devuelven estadisticos F (F_values), entrenando un modelo lineal entre las variables independientes y la objetivo en el caso de regresion, y un test ANOVA en el caso de clasificacion.\n",
    "\n",
    "#mutual_info_regression y mutual_info_classif computan el coeficiente de informacion mutua (MIC) entre las variables independientes y la variable objetivo\n",
    "\n",
    "#El coeficiente de informacion mutua nos da una medida de la dependencia entre las variables. El MIC entre dos variables es 0 si no hay relacion entre las mismas, y aumenta conforme mas relacion tienen.\n",
    "\n",
    "#El MIC se define como:\n",
    "\n",
    "#con P_xy siendo la probabilidad conjunta de X e Y\n",
    "\n",
    "#El evaluador ch12 calcula el estadistico chi cuadrado y lo convierte a estadisticos F, con el estadistico chi cuadrado definido como "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(506, 10)"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "sel_kbest=SelectKBest(f_regression,k=10)\n",
    "data_kbest=sel_kbest.fit_transform(train,target)\n",
    "data_kbest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['crim', 'zn', 'indus', 'nox', 'rm', 'age', 'rad', 'tax', 'ptratio',\n",
       "       'lstat'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "col_sel_kbest=train.loc[:,sel_kbest.get_support()].columns\n",
    "col_sel_kbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#El parametro scores_ del selector nos devuelve los resultados de la funcion de evaluacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_kbest.scores_[:10]\n",
    "\n",
    "punt_sel_kbest=zip(train.columns,sel_kbest.scores_, sel_kbest.get_support())\n",
    "\n",
    "eval_kbest=sorted(\n",
    "    filter(lambda c: c[2], punt_sel_kbest),\n",
    "    key=lambda c: c[1], reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('lstat', 601.6178711099022, True),\n",
       " ('rm', 471.84673987638683, True),\n",
       " ('ptratio', 175.10554287576002, True),\n",
       " ('indus', 153.95488313610974, True),\n",
       " ('tax', 141.76135657742415, True),\n",
       " ('nox', 112.59148027970087, True),\n",
       " ('crim', 89.48611475768125, True),\n",
       " ('rad', 85.91427766984091, True),\n",
       " ('age', 83.47745921923685, True),\n",
       " ('zn', 75.25764229895405, True)]"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "list(eval_kbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Esto nos permite ver la evaluacion que le da f_regression a cada variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"reg_lineal_sin_seleccion_kbest\"]=evaluate_model(LinearRegression(),data_kbest,target)\n",
    "resultados[\"svr_sin_seleccion_kbest\"]=evaluate_model(SVR(),data_kbest,target)\n",
    "resultados[\"rf_sin_seleccion_kbest\"]=evaluate_model(RandomForestRegressor(),data_kbest,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                fit_time  score_time  test_score  train_score  \\\n",
       "reg_lineal_sin_seleccion        0.004801    0.004001    5.180846     4.609067   \n",
       "svr_sin_seleccion               0.004802    0.003200    5.180846     4.609067   \n",
       "rf_sin_seleccion                0.004719    0.003819    5.180846     4.609067   \n",
       "reg_lineal_sin_seleccion_kbest  0.007202    0.005602    5.180846     4.609067   \n",
       "svr_sin_seleccion_kbest         0.004795    0.007208    5.180846     4.609067   \n",
       "rf_sin_seleccion_kbest          0.006403    0.003201    5.180846     4.609067   \n",
       "\n",
       "                                fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "reg_lineal_sin_seleccion            1.017410        1.250250             1.0   \n",
       "svr_sin_seleccion                   1.017557        1.000000             1.0   \n",
       "rf_sin_seleccion                    1.000000        1.193202             1.0   \n",
       "reg_lineal_sin_seleccion_kbest      1.526171        1.750205             1.0   \n",
       "svr_sin_seleccion_kbest             1.016066        2.252172             1.0   \n",
       "rf_sin_seleccion_kbest              1.356757        1.000089             1.0   \n",
       "\n",
       "                                train_score_idx  \n",
       "reg_lineal_sin_seleccion                    1.0  \n",
       "svr_sin_seleccion                           1.0  \n",
       "rf_sin_seleccion                            1.0  \n",
       "reg_lineal_sin_seleccion_kbest              1.0  \n",
       "svr_sin_seleccion_kbest                     1.0  \n",
       "rf_sin_seleccion_kbest                      1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n      <th>fit_time_idx</th>\n      <th>score_time_idx</th>\n      <th>test_score_idx</th>\n      <th>train_score_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reg_lineal_sin_seleccion</th>\n      <td>0.004801</td>\n      <td>0.004001</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.017410</td>\n      <td>1.250250</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion</th>\n      <td>0.004802</td>\n      <td>0.003200</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.017557</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion</th>\n      <td>0.004719</td>\n      <td>0.003819</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.000000</td>\n      <td>1.193202</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>reg_lineal_sin_seleccion_kbest</th>\n      <td>0.007202</td>\n      <td>0.005602</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.526171</td>\n      <td>1.750205</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion_kbest</th>\n      <td>0.004795</td>\n      <td>0.007208</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.016066</td>\n      <td>2.252172</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion_kbest</th>\n      <td>0.006403</td>\n      <td>0.003201</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.356757</td>\n      <td>1.000089</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "see_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metodos envolventes (wrapper methods)\n",
    "\n",
    "#Los metodos envolventes funcionan de forma similar a los metodos de ranking, sin embargo, en lugar de usar una funcion estadistica independiente del modelo para evaluar las variables. estos metodos usan la funcion de evaluacion o el performance de los modelos como input para decidir que variables elegir (es decir, \"envuelven\" el funcionamiento del estimador).\n",
    "\n",
    "#Esto significa que los metodos de filtrado se pueden aplicar independientemente de la eleccion del modelo, ya que consiideran los modelos como una caja negra que produce evaluaciones, aunque clarom, diferentes modelos produciran diferentes selecciones de variables\n",
    "\n",
    "#scikit-learn implementa un metodo envolvente llamado **recursive feature elimination. \n",
    "#Funciona seleccionando tadas las variables, entrenando el modelo, usando los coeficientes 'coef_' o la importancia de las variables 'feature_importances' en funcion del estimador, y eliminando n variables. Este proceso se repite hasta que se alcanza el numero de variables deseado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "estimate_sel=RandomForestRegressor()\n",
    "sel_rfe_rf=RFE(estimate_sel,n_features_to_select=10)\n",
    "data_rfe_rf=sel_rfe_rf.fit_transform(train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_rfe_rf=sorted(\n",
    "    filter(lambda c: c[2],\n",
    "        zip(\n",
    "            train.columns,\n",
    "            sel_rfe_rf.ranking_,\n",
    "            sel_rfe_rf.get_support()\n",
    "        )\n",
    "    ), key=lambda c: c[1],reverse=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"reg_lineal_sin_rfe_rf\"]=evaluate_model(LinearRegression(),data_rfe_rf,target)\n",
    "resultados[\"svr_sin_rfe_rf\"]=evaluate_model(SVR(),data_rfe_rf,target)\n",
    "resultados[\"rf_sin_rfe_rf\"]=evaluate_model(RandomForestRegressor(),data_rfe_rf,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                fit_time  score_time  test_score  train_score  \\\n",
       "reg_lineal_sin_seleccion        0.004801    0.004001    5.180846     4.609067   \n",
       "svr_sin_seleccion               0.004802    0.003200    5.180846     4.609067   \n",
       "rf_sin_seleccion                0.004719    0.003819    5.180846     4.609067   \n",
       "reg_lineal_sin_seleccion_kbest  0.004065    0.004810    5.180846     4.609067   \n",
       "svr_sin_seleccion_kbest         0.004814    0.005206    5.180846     4.609067   \n",
       "rf_sin_seleccion_kbest          0.004178    0.003250    5.180846     4.609067   \n",
       "\n",
       "                                fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "reg_lineal_sin_seleccion            1.181001        1.250250             1.0   \n",
       "svr_sin_seleccion                   1.181171        1.000000             1.0   \n",
       "rf_sin_seleccion                    1.160791        1.193202             1.0   \n",
       "reg_lineal_sin_seleccion_kbest      1.000000        1.502943             1.0   \n",
       "svr_sin_seleccion_kbest             1.184262        1.626529             1.0   \n",
       "rf_sin_seleccion_kbest              1.027681        1.015435             1.0   \n",
       "\n",
       "                                train_score_idx  \n",
       "reg_lineal_sin_seleccion                    1.0  \n",
       "svr_sin_seleccion                           1.0  \n",
       "rf_sin_seleccion                            1.0  \n",
       "reg_lineal_sin_seleccion_kbest              1.0  \n",
       "svr_sin_seleccion_kbest                     1.0  \n",
       "rf_sin_seleccion_kbest                      1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n      <th>fit_time_idx</th>\n      <th>score_time_idx</th>\n      <th>test_score_idx</th>\n      <th>train_score_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reg_lineal_sin_seleccion</th>\n      <td>0.004801</td>\n      <td>0.004001</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.181001</td>\n      <td>1.250250</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion</th>\n      <td>0.004802</td>\n      <td>0.003200</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.181171</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion</th>\n      <td>0.004719</td>\n      <td>0.003819</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.160791</td>\n      <td>1.193202</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>reg_lineal_sin_seleccion_kbest</th>\n      <td>0.004065</td>\n      <td>0.004810</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.000000</td>\n      <td>1.502943</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion_kbest</th>\n      <td>0.004814</td>\n      <td>0.005206</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.184262</td>\n      <td>1.626529</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion_kbest</th>\n      <td>0.004178</td>\n      <td>0.003250</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.027681</td>\n      <td>1.015435</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "see_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "estimate_sel=RandomForestRegressor()\n",
    "sel_rfecv_rf=RFE(estimate_sel)\n",
    "data_rfecv_rf=sel_rfecv_rf.fit_transform(train,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados[\"reg_lineal_sin_rfecv_rf\"]=evaluate_model(LinearRegression(),data_rfe_rf,target)\n",
    "resultados[\"svr_sin_rfecv_rf\"]=evaluate_model(SVR(),data_rfe_rf,target)\n",
    "resultados[\"rf_sin_rfecv_rf\"]=evaluate_model(RandomForestRegressor(),data_rfe_rf,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                fit_time  score_time  test_score  train_score  \\\n",
       "reg_lineal_sin_seleccion        0.004801    0.004001    5.180846     4.609067   \n",
       "svr_sin_seleccion               0.004802    0.003200    5.180846     4.609067   \n",
       "rf_sin_seleccion                0.004719    0.003819    5.180846     4.609067   \n",
       "reg_lineal_sin_seleccion_kbest  0.004065    0.004810    5.180846     4.609067   \n",
       "svr_sin_seleccion_kbest         0.004814    0.005206    5.180846     4.609067   \n",
       "rf_sin_seleccion_kbest          0.004178    0.003250    5.180846     4.609067   \n",
       "reg_lineal_sin_rfecv_rf         0.005942    0.001672    5.180846     4.609067   \n",
       "svr_sin_rfecv_rf                0.004366    0.002663    5.180846     4.609067   \n",
       "rf_sin_rfecv_rf                 0.004133    0.004053    5.180846     4.609067   \n",
       "\n",
       "                                fit_time_idx  score_time_idx  test_score_idx  \\\n",
       "reg_lineal_sin_seleccion            1.181001        2.393414             1.0   \n",
       "svr_sin_seleccion                   1.181171        1.914349             1.0   \n",
       "rf_sin_seleccion                    1.160791        2.284205             1.0   \n",
       "reg_lineal_sin_seleccion_kbest      1.000000        2.877157             1.0   \n",
       "svr_sin_seleccion_kbest             1.184262        3.113745             1.0   \n",
       "rf_sin_seleccion_kbest              1.027681        1.943898             1.0   \n",
       "reg_lineal_sin_rfecv_rf             1.461660        1.000000             1.0   \n",
       "svr_sin_rfecv_rf                    1.074012        1.593066             1.0   \n",
       "rf_sin_rfecv_rf                     1.016603        2.424389             1.0   \n",
       "\n",
       "                                train_score_idx  \n",
       "reg_lineal_sin_seleccion                    1.0  \n",
       "svr_sin_seleccion                           1.0  \n",
       "rf_sin_seleccion                            1.0  \n",
       "reg_lineal_sin_seleccion_kbest              1.0  \n",
       "svr_sin_seleccion_kbest                     1.0  \n",
       "rf_sin_seleccion_kbest                      1.0  \n",
       "reg_lineal_sin_rfecv_rf                     1.0  \n",
       "svr_sin_rfecv_rf                            1.0  \n",
       "rf_sin_rfecv_rf                             1.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fit_time</th>\n      <th>score_time</th>\n      <th>test_score</th>\n      <th>train_score</th>\n      <th>fit_time_idx</th>\n      <th>score_time_idx</th>\n      <th>test_score_idx</th>\n      <th>train_score_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>reg_lineal_sin_seleccion</th>\n      <td>0.004801</td>\n      <td>0.004001</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.181001</td>\n      <td>2.393414</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion</th>\n      <td>0.004802</td>\n      <td>0.003200</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.181171</td>\n      <td>1.914349</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion</th>\n      <td>0.004719</td>\n      <td>0.003819</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.160791</td>\n      <td>2.284205</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>reg_lineal_sin_seleccion_kbest</th>\n      <td>0.004065</td>\n      <td>0.004810</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.000000</td>\n      <td>2.877157</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_seleccion_kbest</th>\n      <td>0.004814</td>\n      <td>0.005206</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.184262</td>\n      <td>3.113745</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_seleccion_kbest</th>\n      <td>0.004178</td>\n      <td>0.003250</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.027681</td>\n      <td>1.943898</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>reg_lineal_sin_rfecv_rf</th>\n      <td>0.005942</td>\n      <td>0.001672</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.461660</td>\n      <td>1.000000</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>svr_sin_rfecv_rf</th>\n      <td>0.004366</td>\n      <td>0.002663</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.074012</td>\n      <td>1.593066</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>rf_sin_rfecv_rf</th>\n      <td>0.004133</td>\n      <td>0.004053</td>\n      <td>5.180846</td>\n      <td>4.609067</td>\n      <td>1.016603</td>\n      <td>2.424389</td>\n      <td>1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "see_res()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metodos embebidos (Embedded Methods)\n",
    "#Son metodos de seleccion de variables que estan integrados dentro del proceso de entrenamiento de modelos, y son especificos para cada modelo\n",
    "\n",
    "#El ejemplo clasico de metodo embebido de seleccion de variables son los procesos de regularizacion en regresion lineal. Por ejemplo el metodo L1 tiene a convertir los coeficientes de la variables que no funcionan a 0, por lo tanto eliminandolas"
   ]
  }
 ]
}